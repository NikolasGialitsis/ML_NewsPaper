<header><h1>Your Daily Machine Learning Newspaper</h1></header>


| Towards Data Science                                                                                                                                                                                                                                                                                                                                                                                         |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| <p><a href="https://towardsdatascience.com/efficient-time-series-using-pythons-pmdarima-library-f6825407b7f0"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/1200/1*pKpCFuxIIQ1AMDP9EjkoLA.jpeg"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Efficient Time-Series Using Pmdarima Library</a></p>&nbsp;&nbsp;                 |
| <p><a href="https://towardsdatascience.com/what-i-learned-from-stanfords-covid-mrna-vaccine-kaggle-competition-98d3f454eef"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/1200/0*PLN_o824gwYQ32af"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">What I learned from Covid mRNA Vaccine Kaggle competition</a></p>&nbsp;&nbsp;  |
| <p><a href="https://towardsdatascience.com/edit-your-old-photos-with-machine-learning-computational-photography-7ef27f40cfdf"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/800/1*I8e_EmdhIxdJ2aqRibjBEg.jpeg"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Edit Your Old Photos with Machine Photography</a></p>&nbsp;&nbsp; |
| <p><a href="https://towardsdatascience.com/probability-distribution-an-intuition-for-data-scientists-72d68a8feb4"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/800/0*a_4mhWCfsRvAoDE7"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Probability distribution: an intuition for data scientists</a></p>&nbsp;&nbsp;            |
| <p><a href="https://towardsdatascience.com/private-docker-repositories-for-data-science-with-azure-cccb2b37a647"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/800/0*pY4Ik37eGgxFI2ds"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Private Docker repositories for data science with Azure</a></p>&nbsp;&nbsp;               |
| <p><a href="https://towardsdatascience.com/4-scikit-learn-tools-every-data-scientist-should-use-4ee942958d9e"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/800/1*aaRQT2fLrR8T33t377WVRQ.png"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">4 Scikit-Learn Tools Every Data Scientist Should Use</a></p>&nbsp;&nbsp;            |
| <p><a href="https://towardsdatascience.com/machine-learning-mini-project-6f67e511ffd3"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/800/1*411eDRja1cgc6gRRWVcHNQ.jpeg"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Machine Learning Mini-Project</a></p>&nbsp;&nbsp;                                                        |
| <p><a href="https://towardsdatascience.com/variational-inference-for-neural-networks-a4b5cf72b24"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/800/1*npNCAtYcY2oJWcaUycvBzA.jpeg"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Variational Inference for Neural Networks</a></p>&nbsp;&nbsp;                                  |
| <p><a href="https://towardsdatascience.com/how-to-get-the-most-out-of-towards-data-science-3bf37f75a345"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/2400/gradv/29/81/30/darken/25/1*AO2RBrRUBSqUpbysfzSEWA.jpeg"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Make it a habit</a></p>&nbsp;&nbsp;                          |
| <p><a href="https://towardsdatascience.com/market-intelligence-powered-by-deep-learning-bb63dae49481"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/800/0*RaWDKCcOCfGvAxUt"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Dec 13, 2018</a></p>&nbsp;&nbsp;                                                                      |
| <p><a href="https://towardsdatascience.com/image-segmentation-change-the-color-of-your-car-step-by-step-guide-ba9aa16ee52e"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/800/1*soOUga2SLJawx6D9CKfx3g.png"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Bogdan Militaru</a></p>&nbsp;&nbsp;                                  |
| <p><a href="https://towardsdatascience.com/saliency-map-using-pytorch-68270fe45e80"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/800/1*znhdrsr7dPk0lCMeGxMNKQ.jpeg"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">David</a></p>&nbsp;&nbsp;                                                                                    |
| <p><a href="https://towardsdatascience.com/universal-approximation-theorem-code-refactoring-for-software-2-0-20d4bdc3cf48"><img width="100" height="80" align='right' src="https://cdn-images-1.medium.com/max/800/0*XuGO_aywEizPUYDl"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Irfan Alghani Khalid</a></p>&nbsp;&nbsp;                                        |
| <p><a href="https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac"><img width="100" height="80" align='left' src="https://cdn-images-1.medium.com/max/800/1*Tid5h9TjJXtaUC4gu9riFw.png"                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Michael Li</a></p>&nbsp;&nbsp;                                                                            |
| <p><a href="https://towardsdatascience.com/7-popular-activation-functions-you-should-know-in-deep-learning-and-how-to-use-them-with-keras-and-27b4d838dfe6"><img width="100" height="80" align='right' src=""                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Dec 30, 2020</a></p>&nbsp;&nbsp;                                                                         |
| <p><a href=""><img width="100" height="80" align='left' src=""                     alt="Image Missing" style="vertical-align:middle;margin:50px 0px">Jan 3</a></p>&nbsp;&nbsp;                                                                                                                                                                                                                               |

| title                                                                                                                                                       | abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|-------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| generic machine learning inference on heterogenous treatment effects in   randomized experiments                                                            | we propose strategies to estimate and make inference on key features of heterogeneous effects in randomized experiments. these key features include best linear predictors of the effects on machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. the approach is valid in high dimensional settings, where the effects are proxied by machine learning methods. we post-process these proxies into the estimates of the key features. our approach is generic, it can be used in conjunction with penalized methods, deep and shallow neural networks, canonical and new random forests, boosted trees, and ensemble methods. estimation and inference are based on repeated data splitting to avoid overfitting and achieve validity. for inference, we take medians of p-values and medians of confidence intervals, resulting from many different data splits, and then adjust their nominal level to guarantee uniform validity. this variational inference method, which quantifies the uncertainty coming from both parameter estimation and data splitting, is shown to be uniformly valid for a large class of data generating processes. we illustrate the use of the approach with a randomized field experiment that evaluated a combination of nudges to stimulate demand for immunization in india.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| learning temporal point processes via reinforcement learning                                                                                                | social goods, such as healthcare, smart city, and information networks, often produce ordered event data in continuous time. the generative processes of these event data can be very complex, requiring flexible models to capture their dynamics. temporal point processes offer an elegant framework for modeling event data without discretizing the time. however, the existing maximum-likelihood-estimation (mle) learning paradigm requires hand-crafting the intensity function beforehand and cannot directly monitor the goodness-of-fit of the estimated model in the process of training. to alleviate the risk of model-misspecification in mle, we propose to generate samples from the generative model and monitor the quality of the samples in the process of training until the samples and the real data are indistinguishable. we take inspiration from reinforcement learning (rl) and treat the generation of each event as the action taken by a stochastic policy. we parameterize the policy as a flexible recurrent neural network and gradually improve the policy to mimic the observed event distribution. since the reward function is unknown in this setting, we uncover an analytic and nonparametric form of the reward function using an inverse reinforcement learning formulation. this new rl framework allows us to derive an efficient policy gradient algorithm for learning flexible point process models, and we show that it performs well in both synthetic and real data.                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| quantum-inspired canonical correlation analysis for exponentially large   dimensional data	doi:10.1016/j.neunet.2020.11.019                                 | canonical correlation analysis (cca) is a technique to find statistical dependencies between a pair of multivariate data. however, its application to high dimensional data is limited due to the resulting time complexity. while the conventional cca algorithm requires polynomial time, we have developed an algorithm that approximates cca with computational time proportional to the logarithm of the input dimensionality using quantum-inspired computation. the computational efficiency and approximation performance of the proposed quantum-inspired cca (qicca) algorithm are experimentally demonstrated. furthermore, the fast computation of qicca allows us to directly apply cca even after nonlinearly mapping raw input data into very high dimensional spaces. experiments performed using a benchmark dataset demonstrated that, by mapping the raw input data into the high dimensional spaces with second-order monomials, the proposed qicca extracted more correlations than linear cca and was comparable to deep cca and kernel cca. these results suggest that qicca is considerably useful and quantum-inspired computation has the potential to unlock a new field in which exponentially large dimensional data can be analyzed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| learning algebraic models of quantum entanglement	doi:10.1007/s11128-020-02785-4                                                                            | we review supervised learning and deep neural network design for learning membership on algebraic varieties. we demonstrate that these trained artificial neural networks can predict the entanglement type for quantum states. we give examples for detecting degenerate states, as well as border rank classification for up to 5 binary qubits and 3 qutrits (ternary qubits).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| adversarial $\alpha$-divergence minimization for bayesian approximate   inference	doi:10.1016/j.neucom.2020.09.076                                          | neural networks are popular state-of-the-art models for many different tasks.they are often trained via back-propagation to find a value of the weights that correctly predicts the observed data. although back-propagation has shown good performance in many applications, it cannot easily output an estimate of the uncertainty in the predictions made. estimating the uncertainty in the predictions is a critical aspect with important applications, and one method to obtain this information is following a bayesian approach to estimate a posterior distribution on the model parameters. this posterior distribution summarizes which parameter values are compatible with the data, but is usually intractable and has to be approximated. several mechanisms have been considered for solving this problem. we propose here a general method for approximate bayesian inference that is based on minimizing{\alpha}-divergences and that allows for flexible approximate distributions. the method is evaluated in the context of bayesian neural networks on extensive experiments. the results show that, in regression problems, it often gives better performance in terms of the test log-likelihoodand sometimes in terms of the squared error. in classification problems, however, it gives competitive results.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| convolutions of totally positive distributions with applications to   kernel density estimation                                                             | in this work we study the estimation of the density of a totally positive random vector. total positivity of the distribution of a random vector implies a strong form of positive dependence between its coordinates and, in particular, it implies positive association. since estimating a totally positive density is a non-parametric problem, we take on a (modified) kernel density estimation approach. our main result is that the sum of scaled standard gaussian bumps centered at a min-max closed set provably yields a totally positive distribution. hence, our strategy for producing a totally positive estimator is to form the min-max closure of the set of samples, and output a sum of gaussian bumps centered at the points in this set. we can frame this sum as a convolution between the uniform distribution on a min-max closed set and a scaled standard gaussian. we further conjecture that convolving any totally positive density with a standard gaussian remains totally positive.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| sampling the "inverse set" of a neuron: an approach to understanding   neural nets                                                                          | with the recent success of deep neural networks in computer vision, it is important to understand the internal working of these networks. what does a given neuron represent? the concepts captured by a neuron may be hard to understand or express in simple terms. the approach we propose in this paper is to characterize the region of input space that excites a given neuron to a certain level; we call this the inverse set. this inverse set is a complicated high dimensional object that we explore by an optimization-based sampling approach. inspection of samples of this set by a human can reveal regularities that help to understand the neuron. this goes beyond approaches which were limited to finding an image which maximally activates the neuron or using markov chain monte carlo to sample images, but this is very slow, generates samples with little diversity and lacks control over the activation value of the generated samples. our approach also allows us to explore the intersection of inverse sets of several neurons and other variations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| active bayesian assessment for black-box classifiers                                                                                                        | recent advances in machine learning have led to increased deployment of black-box classifiers across a wide variety of applications. in many such situations there is a critical need to both reliably assess the performance of these pre-trained models and to perform this assessment in a label-efficient manner (given that labels may be scarce and costly to collect). in this paper, we introduce an active bayesian approach for assessment of classifier performance to satisfy the desiderata of both reliability and label-efficiency. we begin by developing inference strategies to quantify uncertainty for common assessment metrics such as accuracy, misclassification cost, and calibration error. we then propose a general framework for active bayesian assessment using inferred uncertainty to guide efficient selection of instances for labeling, enabling better performance assessment with fewer labels. we demonstrate significant gains from our proposed active bayesian approach via a series of systematic empirical experiments assessing the performance of modern neural classifiers (e.g., resnet and bert) on several standard image and text classification datasets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| deep sigma point processes                                                                                                                                  | we introduce deep sigma point processes, a class of parametric models inspired by the compositional structure of deep gaussian processes (dgps). deep sigma point processes (dspps) retain many of the attractive features of (variational) dgps, including mini-batch training and predictive uncertainty that is controlled by kernel basis functions. importantly, since dspps admit a simple maximum likelihood inference procedure, the resulting predictive distributions are not degraded by any posterior approximations. in an extensive empirical comparison on univariate and multivariate regression tasks we find that the resulting predictive distributions are significantly better calibrated than those obtained with other probabilistic methods for scalable regression, including variational dgps--often by as much as a nat per datapoint.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| deep learning for frame error prediction using a darpa spectrum   collaboration challenge (sc2) dataset                                                     | we demonstrate a first example for employing deep learning in predicting frame errors for a collaborative intelligent radio network (cirn) using a dataset collected during participation in the final scrimmages of the darpa sc2 challenge. four scenarios are considered based on randomizing or fixing the strategy for bandwidth and channel allocation, and either training and testing with different links or using a pilot phase for each link to train the deep neural network. we also investigate the effect of latency constraints, and uncover interesting characteristics of the predictor over different signal to noise ratio (snr) ranges. the obtained insights open the door for implementing a deep-learning-based strategy that is scalable to large heterogeneous networks, generalizable to diverse wireless environments, and suitable for predicting frame error instances and rates within a congested shared spectrum.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| kernel-based approximation of the koopman generator and schr\"odinger   operator                                                                            | many dimensionality and model reduction techniques rely on estimating dominant eigenfunctions of associated dynamical operators from data. important examples include the koopman operator and its generator, but also the schr\"odinger operator. we propose a kernel-based method for the approximation of differential operators in reproducing kernel hilbert spaces and show how eigenfunctions can be estimated by solving auxiliary matrix eigenvalue problems. the resulting algorithms are applied to molecular dynamics and quantum chemistry examples. furthermore, we exploit that, under certain conditions, the schr\"odinger operator can be transformed into a kolmogorov backward operator corresponding to a drift-diffusion process and vice versa. this allows us to apply methods developed for the analysis of high-dimensional stochastic differential equations to quantum mechanical systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| neural networks with small weights and depth-separation barriers                                                                                            | in studying the expressiveness of neural networks, an important question is whether there are functions which can only be approximated by sufficiently deep networks, assuming their size is bounded. however, for constant depths, existing results are limited to depths $2$ and $3$, and achieving results for higher depths has been an important open question. in this paper, we focus on feedforward relu networks, and prove fundamental barriers to proving such results beyond depth $4$, by reduction to open problems and natural-proof barriers in circuit complexity. to show this, we study a seemingly unrelated problem of independent interest: namely, whether there are polynomially-bounded functions which require super-polynomial weights in order to approximate with constant-depth neural networks. we provide a negative and constructive answer to that question, by showing that if a function can be approximated by a polynomially-sized, constant depth $k$ network with arbitrarily large weights, it can also be approximated by a polynomially-sized, depth $3k+3$ network, whose weights are polynomially bounded.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| automated design space exploration for optimised deployment of dnn on   arm cortex-a cpus	doi:10.1109/tcad.2020.3046568                                     | the spread of deep learning on embedded devices has prompted the development of numerous methods to optimise the deployment of deep neural networks (dnn). works have mainly focused on: i) efficient dnn architectures, ii) network optimisation techniques such as pruning and quantisation, iii) optimised algorithms to speed up the execution of the most computational intensive layers and, iv) dedicated hardware to accelerate the data flow and computation. however, there is a lack of research on cross-level optimisation as the space of approaches becomes too large to test and obtain a globally optimised solution. thus, leading to suboptimal deployment in terms of latency, accuracy, and memory. in this work, we first detail and analyse the methods to improve the deployment of dnns across the different levels of software optimisation. building on this knowledge, we present an automated exploration framework to ease the deployment of dnns. the framework relies on a reinforcement learning search that, combined with a deep learning inference framework, automatically explores the design space and learns an optimised solution that speeds up the performance and reduces the memory on embedded cpu platforms. thus, we present a set of results for state-of-the-art dnns on a range of arm cortex-a cpu platforms achieving up to 4x improvement in performance and over 2x reduction in memory with negligible loss in accuracy with respect to the blas floating-point implementation.                                                                                                                                                                                                                                                                                                                                                                                                                        |
| deep learning of free boundary and stefan problems	doi:10.1016/j.jcp.2020.109914                                                                            | free boundary problems appear naturally in numerous areas of mathematics, science and engineering. these problems present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of free boundaries and complex dynamic interfaces. in this work, we propose a multi-network model based on physics-informed neural networks to tackle a general class of forward and inverse free boundary problems called stefan problems. specifically, we approximate the unknown solution as well as any moving boundaries by two deep neural networks. besides, we formulate a new type of inverse stefan problems that aim to reconstruct the solution and free boundaries directly from sparse and noisy measurements. we demonstrate the effectiveness of our approach in a series of benchmarks spanning different types of stefan problems, and illustrate how the proposed framework can accurately recover solutions of partial differential equations with moving boundaries and dynamic interfaces. all code and data accompanying this manuscript are publicly available at \url{https://github.com/predictiveintelligencelab/deepstefan}.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| locally private graph neural networks                                                                                                                       | graph neural networks (gnns) have demonstrated superior performance in learning graph representations for several subsequent downstream inference tasks. however, learning over graph data can raise privacy concerns when nodes represent people or human-related variables that involve personal information about individuals. previous works have presented various techniques for privacy-preserving deep learning over non-relational data, such as image, audio, video, and text, but there is less work addressing the privacy issues involved in applying deep learning algorithms on graphs. as a result and for the first time, in this paper, we develop a privacy-preserving gnn learning algorithm with formal privacy guarantees based on local differential privacy (ldp) to tackle the problem of node-level privacy, where graph nodes have potentially sensitive features that need to be kept private, but they could be beneficial for an untrusted server to learn richer node representations. specifically, we propose an optimized ldp algorithm with an unbiased estimator, using which a central server can communicate with the graph nodes to privately collect their data and estimate the graph convolution layer of the gnn. to further reduce the effect of the injected noise, we propose a simple graph convolution layer based on the multi-hop aggregation of the nodes' features. extensive experiments conducted over real-world datasets demonstrate the capability of our method in maintaining an appropriate privacy-accuracy trade-off for privacy-preserving node classification.                                                                                                                                                                                                                                                                                                                                 |
| pac-bayes analysis beyond the usual bounds                                                                                                                  | we focus on a stochastic learning model where the learner observes a finite set of training examples and the output of the learning process is a data-dependent distribution over a space of hypotheses. the learned data-dependent distribution is then used to make randomized predictions, and the high-level theme addressed here is guaranteeing the quality of predictions on examples that were not seen during training, i.e. generalization. in this setting the unknown quantity of interest is the expected risk of the data-dependent randomized predictor, for which upper bounds can be derived via a pac-bayes analysis, leading to pac-bayes bounds.   specifically, we present a basic pac-bayes inequality for stochastic kernels, from which one may derive extensions of various known pac-bayes bounds as well as novel bounds. we clarify the role of the requirements of fixed 'data-free' priors, bounded losses, and i.i.d. data. we highlight that those requirements were used to upper-bound an exponential moment term, while the basic pac-bayes theorem remains valid without those restrictions. we present three bounds that illustrate the use of data-dependent priors, including one for the unbounded square loss.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| dynnet: physics-based neural architecture design for linear and   nonlinear structural response modeling and prediction	doi:10.1016/j.engstruct.2020.111582 | data-driven models for predicting dynamic responses of linear and nonlinear systems are of great importance due to their wide application from probabilistic analysis to inverse problems such as system identification and damage diagnosis. in this study, a physics-based recurrent neural network model is designed that is able to learn the dynamics of linear and nonlinear multiple degrees of freedom systems given a ground motion. the model is able to estimate a complete set of responses, including displacement, velocity, acceleration, and internal forces. compared to the most advanced counterparts, this model requires a smaller number of trainable variables while the accuracy of predictions is higher for long trajectories. in addition, the architecture of the recurrent block is inspired by differential equation solver algorithms and it is expected that this approach yields more generalized solutions. in the training phase, we propose multiple novel techniques to dramatically accelerate the learning process using smaller datasets, such as hardsampling, utilization of trajectory loss function, and implementation of a trust-region approach. numerical case studies are conducted to examine the strength of the network to learn different nonlinear behaviors. it is shown that the network is able to capture different nonlinear behaviors of dynamic systems with very high accuracy and with no need for prior information or very large datasets.                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| efficient marginalization of discrete and structured latent variables   via sparsity                                                                        | training neural network models with discrete (categorical or structured) latent variables can be computationally challenging, due to the need for marginalization over large or combinatorial sets. to circumvent this issue, one typically resorts to sampling-based approximations of the true marginal, requiring noisy gradient estimators (e.g., score function estimator) or continuous relaxations with lower-variance reparameterized gradients (e.g., gumbel-softmax). in this paper, we propose a new training strategy which replaces these estimators by an exact yet efficient marginalization. to achieve this, we parameterize discrete distributions over latent assignments using differentiable sparse mappings: sparsemax and its structured counterparts. in effect, the support of these distributions is greatly reduced, which enables efficient marginalization. we report successful results in three tasks covering a range of latent variable modeling applications: a semisupervised deep generative model, a latent communication game, and a generative model with a bit-vector latent representation. in all cases, we obtain good performance while still achieving the practicality of sampling-based approximations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| aegcn: an autoencoder-constrained graph convolutional network                                                                                               | we propose a novel neural network architecture, called autoencoder-constrained graph convolutional network, to solve node classification task on graph domains. as suggested by its name, the core of this model is a convolutional network operating directly on graphs, whose hidden layers are constrained by an autoencoder. comparing with vanilla graph convolutional networks, the autoencoder step is added to reduce the information loss brought by laplacian smoothing. we consider applying our model on both homogeneous graphs and heterogeneous graphs. for homogeneous graphs, the autoencoder approximates the adjacency matrix of the input graph by taking hidden layer representations as encoder and another one-layer graph convolutional network as decoder. for heterogeneous graphs, since there are multiple adjacency matrices corresponding to different types of edges, the autoencoder approximates the feature matrix of the input graph instead, and changes the encoder to a particularly designed multi-channel pre-processing network with two layers. in both cases, the error occurred in the autoencoder approximation goes to the penalty term in the loss function. in extensive experiments on citation networks and other heterogeneous graphs, we demonstrate that adding autoencoder constraints significantly improves the performance of graph convolutional networks. we also notice that such technique can be applied on graph attention network to improve the performance as well. this reveals the wide applicability of the proposed autoencoder technique.                                                                                                                                                                                                                                                                                                                                               |
| a topological framework for deep learning                                                                                                                   | we utilize classical facts from topology to show that the classification problem in machine learning is always solvable under very mild conditions. furthermore, we show that a softmax classification network acts on an input topological space by a finite sequence of topological moves to achieve the classification task. moreover, given a training dataset, we show how topological formalism can be used to suggest the appropriate architectural choices for neural networks designed to be trained as classifiers on the data. finally, we show how the architecture of a neural network cannot be chosen independently from the shape of the underlying data. to demonstrate these results, we provide example datasets and show how they are acted upon by neural nets from this topological perspective.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| multimodal safety-critical scenarios generation for decision-making   algorithms evaluation                                                                 | existing neural network-based autonomous systems are shown to be vulnerable against adversarial attacks, therefore sophisticated evaluation on their robustness is of great importance. however, evaluating the robustness only under the worst-case scenarios based on known attacks is not comprehensive, not to mention that some of them even rarely occur in the real world. in addition, the distribution of safety-critical data is usually multimodal, while most traditional attacks and evaluation methods focus on a single modality. to solve the above challenges, we propose a flow-based multimodal safety-critical scenario generator for evaluating decisionmaking algorithms. the proposed generative model is optimized with weighted likelihood maximization and a gradient-based sampling procedure is integrated to improve the sampling efficiency. the safety-critical scenarios are generated by querying the task algorithms and the log-likelihood of the generated scenarios is in proportion to the risk level. experiments on a self-driving task demonstrate our advantages in terms of testing efficiency and multimodal modeling capability. we evaluate six reinforcement learning algorithms with our generated traffic scenarios and provide empirical conclusions about their robustness.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| simplicial neural networks                                                                                                                                  | we present simplicial neural networks (snns), a generalization of graph neural networks to data that live on a class of topological spaces called simplicial complexes. these are natural multi-dimensional extensions of graphs that encode not only pairwise relationships but also higher-order interactions between vertices - allowing us to consider richer data, including vector fields and $n$-fold collaboration networks. we define an appropriate notion of convolution that we leverage to construct the desired convolutional neural networks. we test the snns on the task of imputing missing data on coauthorship complexes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| a machine learning framework for computing the most probable paths of   stochastic dynamical systems                                                        | the emergence of transition phenomena between metastable states induced by noise plays a fundamental role in a broad range of nonlinear systems. the computation of the most probable paths is a key issue to understand the mechanism of transition behaviors. shooting method is a common technique for this purpose to solve the euler-lagrange equation for the associated action functional, while losing its efficacy in high-dimensional systems. in the present work, we develop a machine learning framework to compute the most probable paths in the sense of onsager-machlup action functional theory. specifically, we reformulate the boundary value problem of hamiltonian system and design a neural network to remedy the shortcomings of shooting method. the successful applications of our algorithms to several prototypical examples demonstrate its efficacy and accuracy for stochastic systems with both (gaussian) brownian noise and (non-gaussian) l\'evy noise. this novel approach is effective in exploring the internal mechanisms of rare events triggered by random fluctuations in various scientific fields.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| towards compact neural networks via end-to-end training: a bayesian   tensor approach with automatic rank determination                                     | while post-training model compression can greatly reduce the inference cost of a deep neural network, uncompressed training still consumes a huge amount of hardware resources, run-time and energy. it is highly desirable to directly train a compact neural network from scratch with low memory and low computational cost. low-rank tensor decomposition is one of the most effective approaches to reduce the memory and computing requirements of large-size neural networks. however, directly training a low-rank tensorized neural network is a very challenging task because it is hard to determine a proper tensor rank {\it a priori}, which controls the model complexity and compression ratio in the training process. this paper presents a novel end-to-end framework for low-rank tensorized training of neural networks. we first develop a flexible bayesian model that can handle various low-rank tensor formats (e.g., cp, tucker, tensor train and tensor-train matrix) that compress neural network parameters in training. this model can automatically determine the tensor ranks inside a nonlinear forward model, which is beyond the capability of existing bayesian tensor methods. we further develop a scalable stochastic variational inference solver to estimate the posterior density of large-scale problems in training. our work provides the first general-purpose rank-adaptive framework for end-to-end tensorized training. our numerical results on various neural network architectures show orders-of-magnitude parameter reduction and little accuracy loss (or even better accuracy) in the training process. specifically, on a very large deep learning recommendation system with over $4.2\times 10^9$ model parameters, our method can reduce the variables to only $1.6\times 10^5$ automatically in the training process (i.e., by $2.6\times 10^4$ times) while achieving almost the same accuracy. |
| reproducible workflow                                                                                                                                       | reproducibility has been consistently identified as an important component of scientific research. although there is a general consensus on the importance of reproducibility along with the other commonly used 'r' terminology (i.e., replicability, repeatability etc.), there is some disagreement on the usage of these terms, including conflicting definitions used by different parts of the research community. in this encyclopedia article, we explore the different definitions used in scientific literature (specifically pertaining to computational research), whether there is a need for a single standardized definition and provide an alternative based on non-functional requirements. we also describe the role of reproducibility (and other r's) in scientific workflows.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| identifying training stop point with noisy labeled data                                                                                                     | training deep neural networks (dnns) with noisy labels is a challenging problem due to over-parameterization. dnns tend to essentially fit on clean samples at a higher rate in the initial stages, and later fit on the noisy samples at a relatively lower rate. thus, with a noisy dataset, the test accuracy increases initially and drops in the later stages. to find an early stopping point at the maximum obtainable test accuracy (mota), recent studies assume either that i) a clean validation set is available or ii) the noise ratio is known, or, both. however, often a clean validation set is unavailable, and the noise estimation can be inaccurate. to overcome these issues, we provide a novel training solution, free of these conditions. we analyze the rate of change of the training accuracy for different noise ratios under different conditions to identify a training stop region. we further develop a heuristic algorithm based on a small-learning assumption to find a training stop point (tsp) at or close to mota. to the best of our knowledge, our method is the first to rely solely on the \textit{training behavior}, while utilizing the entire training set, to automatically find a tsp. we validated the robustness of our algorithm (autotsp) through several experiments on cifar-10, cifar-100, and a real-world noisy dataset for different noise ratios, noise types and architectures.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| using the naive bayes as a discriminative classifier                                                                                                        | for classification tasks, probabilistic models can be categorized into two disjoint classes: generative or discriminative. it depends on the posterior probability computation of the label $x$ given the observation $y$, $p(x | y)$. on the one hand, generative classifiers, like the naive bayes or the hidden markov model (hmm), need the computation of the joint probability $p(x, y)$, before using the bayes rule to compute $p(x | y)$. on the other hand, discriminative classifiers compute $p(x | y)$ directly, regardless of the observations' law. they are intensively used nowadays, with models as logistic regression, conditional random fields (crf), and artificial neural networks. however, the recent entropic forward-backward algorithm shows that the hmm, considered as a generative model, can also match the discriminative one's definition. this example leads to question if it is the case for other generative models. in this paper, we show that the naive bayes classifier can also match the discriminative classifier definition, so it can be used in either a generative or a discriminative way. moreover, this observation also discusses the notion of generative-discriminative pairs, linking, for example, naive bayes and logistic regression, or hmm and crf. related to this point, we show that the logistic regression can be viewed as a particular case of the naive bayes used in a discriminative way.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| robustness, privacy, and generalization of adversarial training                                                                                             | adversarial training can considerably robustify deep neural networks to resist adversarial attacks. however, some works suggested that adversarial training might comprise the privacy-preserving and generalization abilities. this paper establishes and quantifies the privacy-robustness trade-off and generalization-robustness trade-off in adversarial training from both theoretical and empirical aspects. we first define a notion, {\it robustified intensity} to measure the robustness of an adversarial training algorithm. this measure can be approximate empirically by an asymptotically consistent empirical estimator, {\it empirical robustified intensity}. based on the robustified intensity, we prove that (1) adversarial training is $(\varepsilon, \delta)$-differentially private, where the magnitude of the differential privacy has a positive correlation with the robustified intensity; and (2) the generalization error of adversarial training can be upper bounded by an $\mathcal o(\sqrt{\log n}/n)$ on-average bound and an $\mathcal o(1/\sqrt{n})$ high-probability bound, both of which have positive correlations with the robustified intensity. additionally, our generalization bounds do not explicitly rely on the parameter size which would be prohibitively large in deep learning. systematic experiments on standard datasets, cifar-10 and cifar-100, are in full agreement with our theories. the source code package is available at \url{https://github.com/fshp971/rpg}.                                                                                                                                                                                                                                                                                                                                                                                                                           |
| adaptively solving the local-minimum problem for deep neural networks                                                                                       | this paper aims to overcome a fundamental problem in the theory and application of deep neural networks (dnns). we propose a method to solve the local minimum problem in training dnns directly. our method is based on the cross-entropy loss criterion's convexification by transforming the cross-entropy loss into a risk averting error (rae) criterion. to alleviate numerical difficulties, a normalized rae (nrae) is employed. the convexity region of the cross-entropy loss expands as its risk sensitivity index (rsi) increases. making the best use of the convexity region, our method starts training with an extensive rsi, gradually reduces it, and switches to the rae as soon as the rae is numerically feasible. after training converges, the resultant deep learning machine is expected to be inside the attraction basin of a global minimum of the cross-entropy loss. numerical results are provided to show the effectiveness of the proposed method.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ranking and rejecting of pre-trained deep neural networks in transfer   learning based on separation index                                                  | automated ranking of pre-trained deep neural networks (dnns) reduces the required time for selecting optimal pre-trained dnn and boost the classification performance in transfer learning. in this paper, we introduce a novel algorithm to rank pre-trained dnns by applying a straightforward distance-based complexity measure named separation index (si) to the target dataset. for this purpose, at first, a background about the si is given and then the automated ranking algorithm is explained. in this algorithm, the si is computed for the target dataset which passes from the feature extracting parts of pre-trained dnns. then, by descending sort of the computed sis, the pre-trained dnns are ranked, easily. in this ranking method, the best dnn makes maximum si on the target dataset and a few pre-trained dnns may be rejected in the case of their sufficiently low computed sis. the efficiency of the proposed algorithm is evaluated by using three challenging datasets including linnaeus 5, breast cancer images, and covid-ct. for the two first case studies, the results of the proposed algorithm exactly match with the ranking of the trained dnns by the accuracy on the target dataset. for the third case study, despite using different preprocessing on the target data, the ranking of the algorithm has a high correlation with the ranking resulted from classification accuracy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| universal approximation theorem for equivariant maps by group cnns                                                                                          | group symmetry is inherent in a wide variety of data distributions. data processing that preserves symmetry is described as an equivariant map and often effective in achieving high performance. convolutional neural networks (cnns) have been known as models with equivariance and shown to approximate equivariant maps for some specific groups. however, universal approximation theorems for cnns have been separately derived with individual techniques according to each group and setting. this paper provides a unified method to obtain universal approximation theorems for equivariant maps by cnns in various settings. as its significant advantage, we can handle non-linear equivariant maps between infinite-dimensional spaces for non-compact groups.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| mathematical models of overparameterized neural networks	doi:10.1109/jproc.2020.3048020                                                                     | deep learning has received considerable empirical successes in recent years. however, while many ad hoc tricks have been discovered by practitioners, until recently, there has been a lack of theoretical understanding for tricks invented in the deep learning literature. known by practitioners that overparameterized neural networks are easy to learn, in the past few years there have been important theoretical developments in the analysis of overparameterized neural networks. in particular, it was shown that such systems behave like convex systems under various restricted settings, such as for two-layer nns, and when learning is restricted locally in the so-called neural tangent kernel space around specialized initializations. this paper discusses some of these recent progresses leading to significant better understanding of neural networks. we will focus on the analysis of two-layer neural networks, and explain the key mathematical models, with their algorithmic implications. we will then discuss challenges in understanding deep neural networks and some current research directions.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| risk-sensitive deep rl: variance-constrained actor-critic provably finds   globally optimal policy                                                          | while deep reinforcement learning has achieved tremendous successes in various applications, most existing works only focus on maximizing the expected value of total return and thus ignore its inherent stochasticity. such stochasticity is also known as the aleatoric uncertainty and is closely related to the notion of risk. in this work, we make the first attempt to study risk-sensitive deep reinforcement learning under the average reward setting with the variance risk criteria. in particular, we focus on a variance-constrained policy optimization problem where the goal is to find a policy that maximizes the expected value of the long-run average reward, subject to a constraint that the long-run variance of the average reward is upper bounded by a threshold. utilizing lagrangian and fenchel dualities, we transform the original problem into an unconstrained saddle-point policy optimization problem, and propose an actor-critic algorithm that iteratively and efficiently updates the policy, the lagrange multiplier, and the fenchel dual variable. when both the value and policy functions are represented by multi-layer overparameterized neural networks, we prove that our actor-critic algorithm generates a sequence of policies that finds a globally optimal policy at a sublinear rate.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| catastrophic fisher explosion: early phase fisher matrix impacts   generalization                                                                           | the early phase of training has been shown to be important in two ways for deep neural networks. first, the degree of regularization in this phase significantly impacts the final generalization. second, it is accompanied by a rapid change in the local loss curvature influenced by regularization choices. connecting these two findings, we show that stochastic gradient descent (sgd) implicitly penalizes the trace of the fisher information matrix (fim) from the beginning of training. we argue it is an implicit regularizer in sgd by showing that explicitly penalizing the trace of the fim can significantly improve generalization. we further show that the early value of the trace of the fim correlates strongly with the final generalization. we highlight that in the absence of implicit or explicit regularization, the trace of the fim can increase to a large value early in training, to which we refer as catastrophic fisher explosion. finally, to gain insight into the regularization effect of penalizing the trace of the fim, we show that 1) it limits memorization by reducing the learning speed of examples with noisy labels more than that of the clean examples, and 2) trajectories with a low initial trace of the fim end in flat minima, which are commonly associated with good generalization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |

| title                                                                                                         | abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
|---------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| occipital and left temporal eeg correlates of phenomenal consciousness	doi:10.1016/b978-0-12-802508-6.00018-1 | in the first section, introduction, we present our experimental design. in the second section, we characterize the grand average occipital and temporal electrical activity correlated with a contrast in access. in the third section, we characterize the grand average occipital and temporal electrical activity correlated with a contrast in phenomenology and conclude characterizing the grand average occipital and temporal electrical activity co-occurring with unconsciousness.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| is there sufficient evidence for criticality in cortical systems?                                             | many studies have found evidence that the brain operates at a critical point, a processus known as self-organized criticality. a recent paper found remarkable scalings suggestive of criticality in systems as different as neural cultures, anesthetized or awake brains. we point out here that the diversity of these states would question any claimed role of criticality in information processing. furthermore, we show that two non-critical systems pass all the tests for criticality, a control that was not provided in the original article. we conclude that such false positives demonstrate that the presence of criticality in the brain is still not proven and that we need better methods that scaling analyses.                                                                                                                                                                                                                                                                                                                                                                  |
| efficiency of local learning rules in threshold-linear associative   networks                                 | we derive the gardner storage capacity for associative networks of threshold linear units, and show that with hebbian learning they can operate closer to such gardner bound than binary networks, and even surpass it. this is largely achieved through a sparsification of the retrieved patterns, which we analyze for theoretical and empirical distributions of activity. as reaching the optimal capacity via non-local learning rules like backpropagation requires slow and neurally implausible training procedures, our results indicate that one-shot self-organized hebbian learning can be just as efficient.                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| real-time optimization of the current steering for visual prosthesis                                          | current steering on a multi-electrode array is commonly used to shape the electric field in the neural tissue in order to improve selectivity and efficacy of stimulation. previously, simulations of the electric field in tissue required separate computation for each set of the stimulation parameters. not only is this approach to modeling time-consuming and very difficult with a large number of electrodes, it is incompatible with real-time optimization of the current steering for practical applications. we present a framework for efficient computation of the electric field in the neural tissue based on superposition of the fields from a pre-calculated basis. such linear algebraic framework enables optimization of the current steering for any targeted electric field in real time. for applications to retinal prosthetics, we demonstrate how the stimulation depth can be optimized for each patient based on the retinal thickness and separation from the array, while maximizing the lateral confinement of the electric field essential for spatial resolution. |
| towards sample-efficient episodic control with dac-ml                                                         | the sample-inefficiency problem in artificial intelligence refers to the inability of current deep reinforcement learning models to optimize action policies within a small number of episodes. recent studies have tried to overcome this limitation by adding memory systems and architectural biases to improve learning speed, such as in episodic reinforcement learning. however, despite achieving incremental improvements, their performance is still not comparable to how humans learn behavioral policies. in this paper, we capitalize on the design principles of the distributed adaptive control (dac) theory of mind and brain to build a novel cognitive architecture (dac-ml) that, by incorporating a hippocampus-inspired sequential memory system, can rapidly converge to effective action policies that maximize reward acquisition in a challenging foraging task.                                                                                                                                                                                                            |